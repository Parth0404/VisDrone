{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9030359,"sourceType":"datasetVersion","datasetId":5439938},{"sourceId":9122899,"sourceType":"datasetVersion","datasetId":5507286},{"sourceId":9031666,"sourceType":"datasetVersion","datasetId":5443742}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"import shutil\nimport os\nfrom pathlib import Path\n\n# Define source and destination directories\nsrc_dir = Path('/kaggle/input/visdrone-videos')\ndst_dir = Path('/kaggle/working/VisDrone')\n\n# Create destination directory if it doesn't exist\ndst_dir.mkdir(parents=True, exist_ok=True)\n\n# Copy dataset to writable directory\nfor item in src_dir.iterdir():\n    s = item\n    d = dst_dir / item.name\n    if item.is_dir():\n        shutil.copytree(s, d, symlinks=True, ignore=shutil.ignore_patterns('*.zip'))\n    else:\n        shutil.copy2(s, d)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T13:37:18.949081Z","iopub.execute_input":"2024-08-04T13:37:18.949448Z","iopub.status.idle":"2024-08-04T13:43:30.476468Z","shell.execute_reply.started":"2024-08-04T13:37:18.949417Z","shell.execute_reply":"2024-08-04T13:43:30.475673Z"}}},{"cell_type":"code","source":"!rm -r /kaggle/working/VisDrone/VisDrone2019-VID-test-dev","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:48:30.475057Z","iopub.execute_input":"2024-08-04T13:48:30.475839Z","iopub.status.idle":"2024-08-04T13:48:31.490187Z","shell.execute_reply.started":"2024-08-04T13:48:30.475804Z","shell.execute_reply":"2024-08-04T13:48:31.489293Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"rm: cannot remove '/kaggle/working/VisDrone/VisDrone2019-VID-test-dev': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# Function to convert VisDrone annotations to YOLO format\ndef visdrone2yolo_batch(dir, batch_size=10):\n    def convert_box(size, box):\n        # Convert VisDrone box to YOLO xywh box\n        dw = 1. / size[0]\n        dh = 1. / size[1]\n        x_center = (box[0] + box[2] / 2) * dw\n        y_center = (box[1] + box[3] / 2) * dh\n        width = box[2] * dw\n        height = box[3] * dh\n        return x_center, y_center, width, height\n\n    labels_dir = dir / 'labels'\n    labels_dir.mkdir(parents=True, exist_ok=True)\n\n    sequences_dir = dir / 'sequences'\n    annotations_dir = dir / 'annotations'\n\n    # Ensure annotations directory exists\n    if not annotations_dir.exists():\n        print(f\"Annotations directory not found: {annotations_dir}\")\n        return\n\n    # Loop through all subdirectories (each representing a video) in the sequences directory\n    video_dirs = list(sequences_dir.iterdir())\n    total_videos = len(video_dirs)\n\n    for batch_start in range(0, total_videos, batch_size):\n        batch_end = min(batch_start + batch_size, total_videos)\n        current_batch = video_dirs[batch_start:batch_end]\n\n        for video_dir in current_batch:\n            if video_dir.is_dir():\n                video_name = video_dir.name\n                annotation_file = annotations_dir / f\"{video_name}.txt\"\n\n                if not annotation_file.exists():\n                    print(f\"Annotation file not found: {annotation_file}\")\n                    continue\n\n                # Read annotation file once\n                with open(annotation_file, 'r') as file:\n                    annotations = [x.split(',') for x in file.read().strip().splitlines()]\n\n                pbar = tqdm(list(video_dir.glob('*.jpg')), desc=f'Converting {video_dir}')\n\n                for image_file in pbar:\n                    frame_number = int(image_file.stem.split('_')[-1])  # Extract frame number\n                    img_size = Image.open(image_file).size\n                    lines = []\n\n                    # Filter annotations for the current frame number\n                    frame_annotations = [row for row in annotations if int(row[0]) == frame_number]\n\n                    for row in frame_annotations:\n                        if row[4] == '0':  # VisDrone 'ignored regions' class 0\n                            continue\n                        cls = int(row[5]) - 1  # Adjust class index\n                        if cls >= 0 and cls <= 9:  # Ensure class is within the valid range\n                            box = tuple(map(int, row[1:5]))  # Adjusted to use correct box indices\n                            yolo_box = convert_box(img_size, box)\n                            lines.append(f\"{cls} {' '.join(f'{x:.6f}' for x in yolo_box)}\\n\")\n\n                    # Save YOLO formatted labels\n                    label_path = labels_dir / f\"{video_name}_{frame_number:06d}.txt\"\n                    with open(label_path, 'w') as fl:\n                        fl.writelines(lines)\n\n                # Remove processed annotation file to free up space\n                os.remove(annotation_file)\n                print(f\"Deleted annotation file: {annotation_file}\")\n\n# Convert annotations for the datasets\nroot_dir = Path('/kaggle/working/VisDrone')\ndatasets = ['VisDrone2019-VID-train/VisDrone2019-VID-train', 'VisDrone2019-VID-val/VisDrone2019-VID-val']\n\nfor d in datasets:\n    visdrone2yolo_batch(root_dir / d)  # Convert VisDrone annotations to YOLO labels\n\nprint(\"Conversion complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:48:52.202085Z","iopub.execute_input":"2024-08-04T13:48:52.202842Z","iopub.status.idle":"2024-08-04T13:51:15.644958Z","shell.execute_reply.started":"2024-08-04T13:48:52.202805Z","shell.execute_reply":"2024-08-04T13:51:15.644100Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000222_03150_v: 100%|██████████| 421/421 [00:01<00:00, 265.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000222_03150_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000140_01590_v: 100%|██████████| 256/256 [00:00<00:00, 320.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000140_01590_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000352_05980_v: 100%|██████████| 196/196 [00:00<00:00, 248.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000352_05980_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000308_00000_v: 100%|██████████| 230/230 [00:00<00:00, 429.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000308_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000076_00720_v: 100%|██████████| 361/361 [00:00<00:00, 649.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000076_00720_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000124_00944_v: 100%|██████████| 398/398 [00:03<00:00, 105.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000124_00944_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000288_00001_v: 100%|██████████| 1424/1424 [00:17<00:00, 82.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000288_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000278_00001_v: 100%|██████████| 962/962 [00:10<00:00, 94.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000278_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000264_02760_v: 100%|██████████| 616/616 [00:02<00:00, 255.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000264_02760_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000270_00001_v: 100%|██████████| 680/680 [00:04<00:00, 151.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000270_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000329_04715_v: 100%|██████████| 196/196 [00:00<00:00, 276.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000329_04715_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000361_02323_v: 100%|██████████| 219/219 [00:01<00:00, 187.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000361_02323_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000013_00000_v: 100%|██████████| 269/269 [00:00<00:00, 537.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000013_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000289_00001_v: 100%|██████████| 500/500 [00:01<00:00, 290.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000289_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000084_00000_v: 100%|██████████| 516/516 [00:03<00:00, 146.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000084_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000126_00001_v: 100%|██████████| 412/412 [00:05<00:00, 80.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000126_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000239_03720_v: 100%|██████████| 680/680 [00:02<00:00, 309.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000239_03720_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000248_00001_v: 100%|██████████| 677/677 [00:04<00:00, 162.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000248_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000072_06432_v: 100%|██████████| 97/97 [00:00<00:00, 512.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000072_06432_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000099_02109_v: 100%|██████████| 1255/1255 [00:02<00:00, 476.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000099_02109_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000363_00001_v: 100%|██████████| 462/462 [00:02<00:00, 177.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000363_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000239_12336_v: 100%|██████████| 341/341 [00:01<00:00, 261.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000239_12336_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000300_00000_v: 100%|██████████| 556/556 [00:02<00:00, 229.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000300_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000360_00001_v: 100%|██████████| 421/421 [00:02<00:00, 205.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000360_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000316_01288_v: 100%|██████████| 127/127 [00:00<00:00, 413.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000316_01288_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000218_00001_v: 100%|██████████| 225/225 [00:00<00:00, 1776.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000218_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000279_00001_v: 100%|██████████| 547/547 [00:05<00:00, 98.21it/s] \n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000279_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000263_03289_v: 100%|██████████| 725/725 [00:01<00:00, 364.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000263_03289_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000307_00000_v: 100%|██████████| 414/414 [00:00<00:00, 565.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000307_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000145_00000_v: 100%|██████████| 307/307 [00:00<00:00, 1100.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000145_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000150_02310_v: 100%|██████████| 348/348 [00:03<00:00, 113.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000150_02310_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000013_01073_v: 100%|██████████| 58/58 [00:00<00:00, 1753.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000013_01073_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000326_01035_v: 100%|██████████| 369/369 [00:02<00:00, 171.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000326_01035_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000366_00001_v: 100%|██████████| 296/296 [00:01<00:00, 199.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000366_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000289_06922_v: 100%|██████████| 210/210 [00:00<00:00, 574.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000289_06922_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000013_01392_v: 100%|██████████| 118/118 [00:00<00:00, 1117.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000013_01392_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000244_01440_v: 100%|██████████| 721/721 [00:06<00:00, 107.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000244_01440_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000138_00000_v: 100%|██████████| 213/213 [00:01<00:00, 174.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000138_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000020_00406_v: 100%|██████████| 501/501 [00:01<00:00, 289.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000020_00406_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000243_00001_v: 100%|██████████| 768/768 [00:03<00:00, 197.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000243_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000323_01173_v: 100%|██████████| 426/426 [00:01<00:00, 238.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000323_01173_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000315_00000_v: 100%|██████████| 632/632 [00:03<00:00, 198.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000315_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000281_00460_v: 100%|██████████| 508/508 [00:02<00:00, 250.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000281_00460_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000072_04488_v: 100%|██████████| 85/85 [00:00<00:00, 510.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000072_04488_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000266_04830_v: 100%|██████████| 116/116 [00:00<00:00, 548.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000266_04830_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000309_00000_v: 100%|██████████| 403/403 [00:01<00:00, 302.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000309_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000295_02300_v: 100%|██████████| 346/346 [00:02<00:00, 145.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000295_02300_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000079_00480_v: 100%|██████████| 361/361 [00:00<00:00, 403.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000079_00480_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000357_00920_v: 100%|██████████| 691/691 [00:09<00:00, 73.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000357_00920_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000308_01380_v: 100%|██████████| 185/185 [00:00<00:00, 346.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000308_01380_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000143_02250_v: 100%|██████████| 261/261 [00:01<00:00, 208.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000143_02250_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000071_03240_v: 100%|██████████| 181/181 [00:00<00:00, 389.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000071_03240_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000342_04692_v: 100%|██████████| 277/277 [00:00<00:00, 385.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000342_04692_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000273_00001_v: 100%|██████████| 872/872 [00:04<00:00, 210.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000273_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000266_03598_v: 100%|██████████| 548/548 [00:00<00:00, 916.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000266_03598_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/sequences/uav0000072_05448_v: 100%|██████████| 217/217 [00:00<00:00, 467.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations/uav0000072_05448_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000305_00000_v: 100%|██████████| 184/184 [00:00<00:00, 673.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000305_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000137_00458_v: 100%|██████████| 233/233 [00:01<00:00, 221.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000137_00458_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000182_00000_v: 100%|██████████| 363/363 [00:01<00:00, 288.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000182_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000268_05773_v: 100%|██████████| 978/978 [00:02<00:00, 378.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000268_05773_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000339_00001_v: 100%|██████████| 275/275 [00:00<00:00, 374.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000339_00001_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000086_00000_v: 100%|██████████| 464/464 [00:02<00:00, 217.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000086_00000_v.txt\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/sequences/uav0000117_02622_v: 100%|██████████| 349/349 [00:01<00:00, 282.10it/s]","output_type":"stream"},{"name":"stdout","text":"Deleted annotation file: /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations/uav0000117_02622_v.txt\nConversion complete.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -r /kaggle/working/VisDrone/VisDrone2019-VID-val/VisDrone2019-VID-val/annotations","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:52:46.852724Z","iopub.execute_input":"2024-08-04T13:52:46.853394Z","iopub.status.idle":"2024-08-04T13:52:47.874846Z","shell.execute_reply.started":"2024-08-04T13:52:46.853363Z","shell.execute_reply":"2024-08-04T13:52:47.873462Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/VisDrone/VisDrone2019-VID-train/VisDrone2019-VID-train/annotations","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:53:28.685965Z","iopub.execute_input":"2024-08-04T13:53:28.686965Z","iopub.status.idle":"2024-08-04T13:53:29.728926Z","shell.execute_reply.started":"2024-08-04T13:53:28.686922Z","shell.execute_reply":"2024-08-04T13:53:29.727556Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm\nimport yaml\n\n# Define YAML content\ncontent = {\n    'path': '/kaggle/working/VisDrone',  # dataset root dir\n    'train': '/kaggle/working/VisDrone/VisDrone-train/Sequences/',  # train images\n    'val': '/kaggle/working/VisDrone/VisDrone-val/Sequences/',  # val images\n    'test': '/kaggle/working/VisDrone/VisDrone-test/Sequences/',  # test images\n    'names': {\n        0: 'pedestrian',\n        1: 'people',\n        2: 'bicycle',\n        3: 'car',\n        4: 'van',\n        5: 'truck',\n        6: 'tricycle',\n        7: 'awning-tricycle',\n        8: 'bus',\n        9: 'motor'\n    }\n}\n\n# Define the path to save the YAML file\nyaml_file_path = '/kaggle/working/dataset.yaml'\n\n# Create the directory if it does not exist\nyaml_dir = os.path.dirname(yaml_file_path)\nif not os.path.exists(yaml_dir):\n    os.makedirs(yaml_dir)\n\n# Write the YAML content to the file\nwith open(yaml_file_path, 'w') as file:\n    yaml.dump(content, file, default_flow_style=False)\n\nprint(f'YAML file created at: {yaml_file_path}')\n\n# Function to convert VisDrone annotations to YOLO format\ndef visdrone2yolo(dir_images, dir_annotations):\n    def convert_box(size, box):\n        # Convert VisDrone box to YOLO xywh box\n        dw = 1. / size[0]\n        dh = 1. / size[1]\n        return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh\n\n    label_dir = dir_annotations.parent / 'labels'\n    label_dir.mkdir(parents=True, exist_ok=True)  # Make labels directory\n\n    pbar = tqdm(dir_annotations.glob('*.txt'), desc=f'Converting {dir_annotations}')\n    for f in pbar:\n        img_filename = f.stem.split('_')[0] + '.jpg'\n        img_path = None\n        for img_dir in dir_images.glob('*/'):\n            possible_img_path = img_dir / img_filename\n            if possible_img_path.exists():\n                img_path = possible_img_path\n                break\n        \n        if img_path is None:\n            continue\n        \n        img_size = Image.open(img_path).size\n        lines = []\n        with open(f, 'r') as file:  # Read annotation.txt\n            for row in [x.split(',') for x in file.read().strip().splitlines()]:\n                if row[4] == '0':  # VisDrone 'ignored regions' class 0\n                    continue\n                cls = int(row[5]) - 1\n                box = convert_box(img_size, tuple(map(int, row[:4])))\n                lines.append(f\"{cls} {' '.join(f'{x:.6f}' for x in box)}\\n\")\n        # Save YOLO formatted labels\n        label_path = label_dir / (f.stem + '.txt')\n        with open(label_path, 'w') as fl:\n            fl.writelines(lines)\n\n# Convert annotations for the datasets\nroot_dir = Path('/kaggle/working/VisDrone')\ndatasets = [\n    ('VisDrone-train/Sequences', 'VisDrone-train/annotations'),\n    ('VisDrone-val/Sequences', 'VisDrone-val/annotations'),\n    ('VisDrone-test/Sequences', 'VisDrone-test/annotations')\n]\n\nfor images_dir, annotations_dir in datasets:\n    visdrone2yolo(root_dir / images_dir, root_dir / annotations_dir)  # Convert VisDrone annotations to YOLO labels\n\nprint(\"Conversion complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:54:00.890786Z","iopub.execute_input":"2024-08-04T13:54:00.891199Z","iopub.status.idle":"2024-08-04T13:54:00.980624Z","shell.execute_reply.started":"2024-08-04T13:54:00.891161Z","shell.execute_reply":"2024-08-04T13:54:00.979668Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"YAML file created at: /kaggle/working/dataset.yaml\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/working/VisDrone/VisDrone-train/annotations: 0it [00:00, ?it/s]\nConverting /kaggle/working/VisDrone/VisDrone-val/annotations: 0it [00:00, ?it/s]\nConverting /kaggle/working/VisDrone/VisDrone-test/annotations: 0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Conversion complete.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import yaml\n\n# Define YAML content\ncontent = {\n    'path': '/kaggle/working/VisDrone/Dataset',  # dataset root dir\n    'train': '/kaggle/working/VisDrone/Dataset/images/train',  # train images\n    'val': '/kaggle/working/VisDrone/Dataset/images/val',  # val images\n    'names': {\n        0: 'pedestrian',\n        1: 'people',\n        2: 'bicycle',\n        3: 'car',\n        4: 'van',\n        5: 'truck',\n        6: 'tricycle',\n        7: 'awning-tricycle',\n        8: 'bus',\n        9: 'motorcycle'\n    }\n}\n\n# Define the path to save the YAML file\nyaml_file_path = '/kaggle/working/VisDrone.yaml'\n\n# Create the directory if it does not exist\nyaml_dir = os.path.dirname(yaml_file_path)\nif not os.path.exists(yaml_dir):\n    os.makedirs(yaml_dir)\n\n# Write the YAML content to the file\nwith open(yaml_file_path, 'w') as file:\n    yaml.dump(content, file, default_flow_style=False)\n\nprint(f'YAML file created at: {yaml_file_path}')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:55:02.008846Z","iopub.execute_input":"2024-08-04T13:55:02.009207Z","iopub.status.idle":"2024-08-04T13:55:02.019513Z","shell.execute_reply.started":"2024-08-04T13:55:02.009176Z","shell.execute_reply":"2024-08-04T13:55:02.018638Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"YAML file created at: /kaggle/working/VisDrone.yaml\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:55:31.383223Z","iopub.execute_input":"2024-08-04T13:55:31.383564Z","iopub.status.idle":"2024-08-04T13:55:48.986718Z","shell.execute_reply.started":"2024-08-04T13:55:31.383537Z","shell.execute_reply":"2024-08-04T13:55:48.985675Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.72-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m605.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.72-py3-none-any.whl (863 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.7/863.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.72 ultralytics-thop-2.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install -U ipywidgets","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:55:48.988441Z","iopub.execute_input":"2024-08-04T13:55:48.988782Z","iopub.status.idle":"2024-08-04T13:56:03.268011Z","shell.execute_reply.started":"2024-08-04T13:55:48.988751Z","shell.execute_reply":"2024-08-04T13:56:03.266896Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nCollecting ipywidgets\n  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.20.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\nCollecting widgetsnbextension~=4.0.11 (from ipywidgets)\n  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.11 (from ipywidgets)\n  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\nDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.7\n    Uninstalling widgetsnbextension-3.6.7:\n      Successfully uninstalled widgetsnbextension-3.6.7\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab-widgets 3.0.9\n    Uninstalling jupyterlab-widgets-3.0.9:\n      Successfully uninstalled jupyterlab-widgets-3.0.9\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\nSuccessfully installed ipywidgets-8.1.3 jupyterlab-widgets-3.0.11 widgetsnbextension-4.0.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip uninstall -y wandb","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:56:07.949862Z","iopub.execute_input":"2024-08-04T13:56:07.950491Z","iopub.status.idle":"2024-08-04T13:56:42.428155Z","shell.execute_reply.started":"2024-08-04T13:56:07.950455Z","shell.execute_reply":"2024-08-04T13:56:42.427032Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found existing installation: wandb 0.17.4\nUninstalling wandb-0.17.4:\n  Successfully uninstalled wandb-0.17.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import ultralytics\nfrom ultralytics import YOLO\n\nmodel=YOLO('yolov8x.pt')\nresults=model.train(data='/kaggle/working/VisDrone.yaml',epochs=20 ,imgsz=640, amp=False, batch=8)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:17:20.717084Z","iopub.execute_input":"2024-08-04T17:17:20.717362Z","iopub.status.idle":"2024-08-04T17:17:21.052811Z","shell.execute_reply.started":"2024-08-04T17:17:20.717338Z","shell.execute_reply":"2024-08-04T17:17:21.051661Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m=\u001b[39mYOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8x.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"],"ename":"ModuleNotFoundError","evalue":"No module named 'ultralytics'","output_type":"error"}]},{"cell_type":"code","source":"import cv2\nimport os\n\ndef create_video_from_frames(input_folder, output_video_path, frame_rate=30):\n    # Get all files in the folder\n    files = sorted([f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))])\n    \n    # Read the first frame to get the dimensions\n    first_frame = cv2.imread(os.path.join(input_folder, files[0]))\n    height, width, layers = first_frame.shape\n\n    # Define the codec and create a VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'mp4v' for .mp4, 'XVID' for .avi\n    video = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n\n    for file in files:\n        frame = cv2.imread(os.path.join(input_folder, file))\n        video.write(frame)\n    \n    video.release()\n\ndef process_all_folders(parent_folder, output_folder):\n    # Ensure the output folder exists\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    # Process each subfolder\n    for subfolder in os.listdir(parent_folder):\n        subfolder_path = os.path.join(parent_folder, subfolder)\n        if os.path.isdir(subfolder_path):\n            output_video_path = os.path.join(output_folder, f\"{subfolder}.mp4\")\n            create_video_from_frames(subfolder_path, output_video_path)\n\n# Set the parent folder where all location folders are stored\nparent_folder = '/kaggle/input/visdrone2019-mot-test/VisDrone2019-MOT-test-challenge/sequences'\noutput_folder = '/kaggle/working/'\n\nprocess_all_folders(parent_folder, output_folder)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T11:03:33.221332Z","iopub.execute_input":"2024-08-08T11:03:33.222047Z","iopub.status.idle":"2024-08-08T11:09:45.241771Z","shell.execute_reply.started":"2024-08-08T11:03:33.222009Z","shell.execute_reply":"2024-08-08T11:09:45.240896Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install supervision","metadata":{"execution":{"iopub.status.busy":"2024-08-08T11:30:18.775775Z","iopub.execute_input":"2024-08-08T11:30:18.776518Z","iopub.status.idle":"2024-08-08T11:30:34.755822Z","shell.execute_reply.started":"2024-08-08T11:30:18.776476Z","shell.execute_reply":"2024-08-08T11:30:34.754589Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting supervision\n  Downloading supervision-0.22.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from supervision) (0.7.1)\nRequirement already satisfied: matplotlib>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from supervision) (3.7.5)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from supervision) (1.26.4)\nRequirement already satisfied: opencv-python-headless>=4.5.5.64 in /opt/conda/lib/python3.10/site-packages (from supervision) (4.10.0.84)\nRequirement already satisfied: pillow>=9.4 in /opt/conda/lib/python3.10/site-packages (from supervision) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from supervision) (6.0.1)\nRequirement already satisfied: scipy<2.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from supervision) (1.11.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\nDownloading supervision-0.22.0-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: supervision\nSuccessfully installed supervision-0.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-08-08T11:31:04.551158Z","iopub.execute_input":"2024-08-08T11:31:04.551556Z","iopub.status.idle":"2024-08-08T11:31:19.722808Z","shell.execute_reply.started":"2024-08-08T11:31:04.551526Z","shell.execute_reply":"2024-08-08T11:31:19.721565Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.74-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m668.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.74-py3-none-any.whl (865 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.5/865.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.74 ultralytics-thop-2.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\n\nmodel = YOLO(\"/kaggle/input/yolov8n-940/yolov8n_940.pt\")\ntracker = sv.ByteTrack()\nbox_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()\ntrace_annotator = sv.TraceAnnotator()\n\ndef callback(frame: np.ndarray, _: int) -> np.ndarray:\n    results = model(frame)[0]\n    detections = sv.Detections.from_ultralytics(results)\n    detections = tracker.update_with_detections(detections)\n\n    labels = [\n        f\"#{tracker_id} {results.names[class_id]}\"\n        for class_id, tracker_id\n        in zip(detections.class_id, detections.tracker_id)\n    ]\n\n    annotated_frame = box_annotator.annotate(\n        frame.copy(), detections=detections)\n    annotated_frame = label_annotator.annotate(\n        annotated_frame, detections=detections, labels=labels)\n    return trace_annotator.annotate(\n        annotated_frame, detections=detections)\n\nsv.process_video(\n    source_path=\"/kaggle/working/uav0000320_03910_v.mp4\",\n    target_path=\"/kaggle/working/1.mp4\",\n    callback=callback\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T11:31:44.406811Z","iopub.execute_input":"2024-08-08T11:31:44.407194Z","iopub.status.idle":"2024-08-08T11:32:00.682344Z","shell.execute_reply.started":"2024-08-08T11:31:44.407163Z","shell.execute_reply":"2024-08-08T11:32:00.681367Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"SupervisionWarnings: BoundingBoxAnnotator is deprecated: `BoundingBoxAnnotator` is deprecated and has been renamed to `BoxAnnotator`. `BoundingBoxAnnotator` will be removed in supervision-0.26.0.\n","output_type":"stream"},{"name":"stdout","text":"\n0: 544x960 39 pedestrians, 1 people, 1 bicycle, 7 cars, 3 tricycles, 12 motors, 123.5ms\nSpeed: 20.9ms preprocess, 123.5ms inference, 320.2ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 39 pedestrians, 2 bicycles, 7 cars, 1 van, 1 truck, 1 tricycle, 1 awning-tricycle, 17 motors, 8.5ms\nSpeed: 7.3ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 51 pedestrians, 1 bicycle, 8 cars, 2 vans, 1 tricycle, 11 motors, 8.4ms\nSpeed: 5.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 39 pedestrians, 1 bicycle, 9 cars, 2 vans, 2 tricycles, 14 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 47 pedestrians, 1 bicycle, 9 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 12 motors, 8.5ms\nSpeed: 5.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 42 pedestrians, 1 bicycle, 12 cars, 1 truck, 1 tricycle, 8 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 48 pedestrians, 1 bicycle, 13 cars, 1 van, 2 tricycles, 1 awning-tricycle, 10 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 41 pedestrians, 1 bicycle, 13 cars, 2 vans, 1 truck, 1 tricycle, 13 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 44 pedestrians, 3 bicycles, 13 cars, 4 vans, 1 tricycle, 9 motors, 8.5ms\nSpeed: 4.5ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 38 pedestrians, 12 cars, 3 vans, 1 truck, 2 tricycles, 13 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 49 pedestrians, 1 people, 14 cars, 2 vans, 10 motors, 8.4ms\nSpeed: 4.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 41 pedestrians, 14 cars, 1 van, 1 truck, 1 tricycle, 8 motors, 8.4ms\nSpeed: 5.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 42 pedestrians, 13 cars, 2 vans, 1 truck, 8 motors, 8.4ms\nSpeed: 3.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 43 pedestrians, 2 peoples, 12 cars, 2 vans, 9 motors, 8.4ms\nSpeed: 5.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 40 pedestrians, 1 bicycle, 11 cars, 2 vans, 1 truck, 1 tricycle, 1 awning-tricycle, 8 motors, 8.4ms\nSpeed: 5.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 37 pedestrians, 3 peoples, 14 cars, 2 vans, 1 truck, 1 tricycle, 1 awning-tricycle, 10 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 44 pedestrians, 4 peoples, 14 cars, 2 vans, 2 trucks, 2 tricycles, 7 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 41 pedestrians, 2 peoples, 14 cars, 2 vans, 1 truck, 2 tricycles, 11 motors, 8.4ms\nSpeed: 5.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 41 pedestrians, 4 peoples, 1 bicycle, 16 cars, 2 vans, 1 truck, 1 tricycle, 10 motors, 8.4ms\nSpeed: 5.5ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 39 pedestrians, 2 peoples, 13 cars, 1 van, 1 tricycle, 1 awning-tricycle, 11 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 34 pedestrians, 3 peoples, 17 cars, 2 vans, 2 tricycles, 12 motors, 8.5ms\nSpeed: 3.8ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 40 pedestrians, 3 peoples, 2 bicycles, 14 cars, 2 vans, 1 awning-tricycle, 10 motors, 8.7ms\nSpeed: 4.6ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 40 pedestrians, 2 peoples, 1 bicycle, 16 cars, 2 vans, 1 truck, 13 motors, 8.4ms\nSpeed: 5.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 38 pedestrians, 1 people, 17 cars, 4 vans, 1 tricycle, 8 motors, 8.4ms\nSpeed: 4.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 38 pedestrians, 3 peoples, 1 bicycle, 18 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 11 motors, 8.4ms\nSpeed: 4.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 43 pedestrians, 3 peoples, 2 bicycles, 19 cars, 1 van, 1 awning-tricycle, 9 motors, 8.6ms\nSpeed: 5.5ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 43 pedestrians, 2 peoples, 17 cars, 2 vans, 1 truck, 12 motors, 8.4ms\nSpeed: 4.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 37 pedestrians, 1 people, 1 bicycle, 17 cars, 2 vans, 1 truck, 11 motors, 8.4ms\nSpeed: 5.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 42 pedestrians, 2 peoples, 1 bicycle, 17 cars, 1 van, 2 tricycles, 1 awning-tricycle, 12 motors, 8.6ms\nSpeed: 3.7ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 39 pedestrians, 1 people, 19 cars, 2 vans, 1 awning-tricycle, 12 motors, 8.4ms\nSpeed: 3.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 42 pedestrians, 2 peoples, 21 cars, 2 vans, 1 awning-tricycle, 12 motors, 8.4ms\nSpeed: 3.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 43 pedestrians, 2 peoples, 1 bicycle, 18 cars, 3 vans, 11 motors, 8.4ms\nSpeed: 5.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 40 pedestrians, 2 peoples, 1 bicycle, 19 cars, 4 vans, 11 motors, 8.4ms\nSpeed: 3.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 34 pedestrians, 2 peoples, 1 bicycle, 23 cars, 2 vans, 1 truck, 2 tricycles, 11 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 36 pedestrians, 3 peoples, 22 cars, 2 vans, 10 motors, 8.4ms\nSpeed: 5.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 36 pedestrians, 3 peoples, 22 cars, 2 vans, 13 motors, 8.5ms\nSpeed: 4.4ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 34 pedestrians, 2 peoples, 19 cars, 4 vans, 10 motors, 9.0ms\nSpeed: 3.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 42 pedestrians, 3 peoples, 16 cars, 4 vans, 11 motors, 8.5ms\nSpeed: 3.8ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 29 pedestrians, 5 peoples, 1 bicycle, 17 cars, 4 vans, 1 tricycle, 11 motors, 9.2ms\nSpeed: 3.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 4 peoples, 17 cars, 4 vans, 2 tricycles, 14 motors, 8.4ms\nSpeed: 5.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 37 pedestrians, 4 peoples, 1 bicycle, 16 cars, 4 vans, 2 tricycles, 8 motors, 8.4ms\nSpeed: 4.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 6 peoples, 17 cars, 5 vans, 2 tricycles, 13 motors, 8.6ms\nSpeed: 4.7ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 24 pedestrians, 5 peoples, 2 bicycles, 18 cars, 4 vans, 1 truck, 12 motors, 8.4ms\nSpeed: 5.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 4 peoples, 1 bicycle, 16 cars, 5 vans, 15 motors, 8.6ms\nSpeed: 3.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 35 pedestrians, 3 peoples, 19 cars, 4 vans, 12 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 42 pedestrians, 1 people, 18 cars, 4 vans, 9 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 43 pedestrians, 2 peoples, 18 cars, 4 vans, 10 motors, 8.4ms\nSpeed: 5.4ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 40 pedestrians, 3 peoples, 2 bicycles, 20 cars, 5 vans, 1 tricycle, 12 motors, 8.4ms\nSpeed: 4.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 38 pedestrians, 2 peoples, 19 cars, 5 vans, 12 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 1 people, 1 bicycle, 19 cars, 4 vans, 1 tricycle, 11 motors, 8.4ms\nSpeed: 3.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 33 pedestrians, 3 peoples, 1 bicycle, 21 cars, 5 vans, 1 tricycle, 12 motors, 8.4ms\nSpeed: 3.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 38 pedestrians, 2 peoples, 1 bicycle, 18 cars, 5 vans, 1 tricycle, 13 motors, 8.4ms\nSpeed: 3.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 37 pedestrians, 3 peoples, 2 bicycles, 20 cars, 5 vans, 2 tricycles, 11 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 33 pedestrians, 2 peoples, 20 cars, 4 vans, 1 tricycle, 13 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 37 pedestrians, 2 peoples, 21 cars, 4 vans, 1 tricycle, 15 motors, 8.5ms\nSpeed: 5.4ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 34 pedestrians, 3 peoples, 21 cars, 3 vans, 1 tricycle, 18 motors, 8.5ms\nSpeed: 3.7ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 39 pedestrians, 3 peoples, 1 bicycle, 22 cars, 2 vans, 1 tricycle, 17 motors, 8.4ms\nSpeed: 4.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 28 pedestrians, 5 peoples, 1 bicycle, 22 cars, 4 vans, 1 tricycle, 16 motors, 8.4ms\nSpeed: 4.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 35 pedestrians, 3 peoples, 22 cars, 3 vans, 1 tricycle, 15 motors, 8.5ms\nSpeed: 5.4ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 29 pedestrians, 2 peoples, 2 bicycles, 22 cars, 4 vans, 1 tricycle, 18 motors, 8.4ms\nSpeed: 4.0ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 36 pedestrians, 2 peoples, 24 cars, 3 vans, 1 tricycle, 16 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 38 pedestrians, 2 peoples, 2 bicycles, 23 cars, 4 vans, 2 tricycles, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 4.5ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 31 pedestrians, 4 peoples, 1 bicycle, 23 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 11 motors, 8.4ms\nSpeed: 4.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 37 pedestrians, 4 peoples, 25 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 16 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 29 pedestrians, 4 peoples, 22 cars, 3 vans, 2 tricycles, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 4.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 35 pedestrians, 3 peoples, 22 cars, 4 vans, 1 truck, 2 tricycles, 1 awning-tricycle, 12 motors, 8.9ms\nSpeed: 3.7ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 4 peoples, 22 cars, 3 vans, 1 truck, 2 tricycles, 1 awning-tricycle, 17 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 27 pedestrians, 4 peoples, 19 cars, 2 vans, 1 tricycle, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 5.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 1 people, 22 cars, 4 vans, 1 tricycle, 2 awning-tricycles, 16 motors, 8.4ms\nSpeed: 5.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 26 pedestrians, 3 peoples, 20 cars, 3 vans, 1 tricycle, 2 awning-tricycles, 10 motors, 8.7ms\nSpeed: 4.1ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 30 pedestrians, 3 peoples, 19 cars, 3 vans, 1 truck, 1 tricycle, 2 awning-tricycles, 14 motors, 8.4ms\nSpeed: 3.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 26 pedestrians, 2 peoples, 20 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 5.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 28 pedestrians, 3 peoples, 21 cars, 2 vans, 1 truck, 1 tricycle, 2 awning-tricycles, 10 motors, 8.4ms\nSpeed: 3.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 32 pedestrians, 1 people, 23 cars, 3 vans, 2 awning-tricycles, 11 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 28 pedestrians, 4 peoples, 24 cars, 3 vans, 14 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 33 pedestrians, 5 peoples, 21 cars, 5 vans, 1 awning-tricycle, 18 motors, 8.4ms\nSpeed: 5.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 28 pedestrians, 6 peoples, 1 bicycle, 23 cars, 4 vans, 1 awning-tricycle, 15 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 31 pedestrians, 6 peoples, 1 bicycle, 24 cars, 4 vans, 1 awning-tricycle, 13 motors, 9.0ms\nSpeed: 4.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 30 pedestrians, 4 peoples, 1 bicycle, 23 cars, 3 vans, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 26 pedestrians, 6 peoples, 21 cars, 3 vans, 2 awning-tricycles, 15 motors, 8.4ms\nSpeed: 5.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 31 pedestrians, 5 peoples, 21 cars, 4 vans, 1 awning-tricycle, 15 motors, 8.4ms\nSpeed: 3.6ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 29 pedestrians, 4 peoples, 20 cars, 4 vans, 1 tricycle, 14 motors, 8.4ms\nSpeed: 3.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 30 pedestrians, 3 peoples, 20 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 12 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 22 pedestrians, 3 peoples, 22 cars, 4 vans, 14 motors, 8.5ms\nSpeed: 5.1ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 26 pedestrians, 4 peoples, 22 cars, 4 vans, 1 tricycle, 3 awning-tricycles, 15 motors, 8.5ms\nSpeed: 4.0ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 26 pedestrians, 8 peoples, 1 bicycle, 21 cars, 3 vans, 1 truck, 1 tricycle, 2 awning-tricycles, 14 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 6 peoples, 22 cars, 3 vans, 19 motors, 8.6ms\nSpeed: 4.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 24 pedestrians, 4 peoples, 2 bicycles, 21 cars, 4 vans, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 5.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 19 pedestrians, 5 peoples, 1 bicycle, 22 cars, 3 vans, 1 truck, 1 tricycle, 15 motors, 8.4ms\nSpeed: 3.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 6 peoples, 1 bicycle, 24 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 3.4ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 19 pedestrians, 3 peoples, 1 bicycle, 23 cars, 4 vans, 1 awning-tricycle, 14 motors, 8.5ms\nSpeed: 5.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 23 pedestrians, 6 peoples, 26 cars, 3 vans, 1 truck, 1 tricycle, 12 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 20 pedestrians, 6 peoples, 1 bicycle, 20 cars, 5 vans, 1 truck, 1 tricycle, 1 awning-tricycle, 10 motors, 8.4ms\nSpeed: 5.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 22 pedestrians, 5 peoples, 1 bicycle, 22 cars, 4 vans, 1 truck, 1 tricycle, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 4.3ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 17 pedestrians, 5 peoples, 1 bicycle, 22 cars, 3 vans, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 5.0ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 5 peoples, 1 bicycle, 22 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 9 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 6 peoples, 1 bicycle, 23 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 13 motors, 8.5ms\nSpeed: 5.0ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 20 pedestrians, 7 peoples, 1 bicycle, 22 cars, 3 vans, 1 tricycle, 3 awning-tricycles, 10 motors, 9.1ms\nSpeed: 4.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 17 pedestrians, 6 peoples, 21 cars, 5 vans, 15 motors, 8.5ms\nSpeed: 5.2ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 17 pedestrians, 7 peoples, 23 cars, 3 vans, 1 tricycle, 2 awning-tricycles, 17 motors, 9.1ms\nSpeed: 3.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 17 pedestrians, 7 peoples, 1 bicycle, 23 cars, 5 vans, 3 awning-tricycles, 1 bus, 15 motors, 8.4ms\nSpeed: 5.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 6 peoples, 23 cars, 4 vans, 17 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 20 pedestrians, 6 peoples, 30 cars, 5 vans, 1 tricycle, 1 awning-tricycle, 17 motors, 8.4ms\nSpeed: 4.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 14 pedestrians, 8 peoples, 25 cars, 5 vans, 1 truck, 13 motors, 8.4ms\nSpeed: 4.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 16 pedestrians, 10 peoples, 26 cars, 3 vans, 1 truck, 1 tricycle, 1 awning-tricycle, 16 motors, 8.4ms\nSpeed: 4.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 18 pedestrians, 8 peoples, 22 cars, 2 vans, 2 awning-tricycles, 17 motors, 8.4ms\nSpeed: 4.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 18 pedestrians, 7 peoples, 24 cars, 2 vans, 2 tricycles, 2 awning-tricycles, 15 motors, 8.4ms\nSpeed: 5.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 17 pedestrians, 6 peoples, 27 cars, 4 vans, 1 tricycle, 19 motors, 8.5ms\nSpeed: 4.8ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 18 pedestrians, 8 peoples, 1 bicycle, 27 cars, 4 vans, 19 motors, 8.4ms\nSpeed: 4.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 18 pedestrians, 8 peoples, 1 bicycle, 29 cars, 4 vans, 1 tricycle, 13 motors, 8.5ms\nSpeed: 4.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 16 pedestrians, 7 peoples, 28 cars, 5 vans, 1 tricycle, 2 awning-tricycles, 14 motors, 8.4ms\nSpeed: 5.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 18 pedestrians, 6 peoples, 29 cars, 4 vans, 1 awning-tricycle, 14 motors, 8.5ms\nSpeed: 4.9ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 6 peoples, 1 bicycle, 26 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 18 motors, 8.4ms\nSpeed: 4.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 21 pedestrians, 10 peoples, 2 bicycles, 27 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 18 pedestrians, 11 peoples, 1 bicycle, 29 cars, 4 vans, 2 tricycles, 1 awning-tricycle, 17 motors, 8.5ms\nSpeed: 3.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 16 pedestrians, 9 peoples, 2 bicycles, 25 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 5.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 16 pedestrians, 8 peoples, 24 cars, 5 vans, 1 tricycle, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 5.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 15 pedestrians, 8 peoples, 2 bicycles, 24 cars, 4 vans, 2 tricycles, 1 awning-tricycle, 14 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 15 pedestrians, 9 peoples, 2 bicycles, 25 cars, 4 vans, 1 tricycle, 13 motors, 8.4ms\nSpeed: 3.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 12 pedestrians, 6 peoples, 2 bicycles, 28 cars, 5 vans, 2 tricycles, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 5.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 13 pedestrians, 9 peoples, 26 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 4.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 14 pedestrians, 12 peoples, 1 bicycle, 25 cars, 6 vans, 3 tricycles, 16 motors, 8.5ms\nSpeed: 4.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 12 pedestrians, 11 peoples, 3 bicycles, 25 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 11 motors, 8.4ms\nSpeed: 3.5ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 10 pedestrians, 12 peoples, 5 bicycles, 26 cars, 4 vans, 1 tricycle, 12 motors, 8.4ms\nSpeed: 5.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 7 pedestrians, 10 peoples, 1 bicycle, 26 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 12 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 8 pedestrians, 11 peoples, 1 bicycle, 28 cars, 3 vans, 2 tricycles, 1 awning-tricycle, 9 motors, 8.4ms\nSpeed: 4.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 6 pedestrians, 14 peoples, 1 bicycle, 26 cars, 5 vans, 1 tricycle, 1 awning-tricycle, 11 motors, 9.0ms\nSpeed: 3.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 6 pedestrians, 15 peoples, 33 cars, 2 vans, 2 tricycles, 1 awning-tricycle, 9 motors, 8.4ms\nSpeed: 5.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 6 pedestrians, 12 peoples, 1 bicycle, 34 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 11 motors, 8.5ms\nSpeed: 3.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 7 pedestrians, 12 peoples, 30 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 10 motors, 8.4ms\nSpeed: 4.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 5 pedestrians, 11 peoples, 30 cars, 4 vans, 1 tricycle, 1 awning-tricycle, 9 motors, 11.9ms\nSpeed: 6.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 6 pedestrians, 14 peoples, 1 bicycle, 32 cars, 3 vans, 1 truck, 1 tricycle, 2 awning-tricycles, 9 motors, 8.6ms\nSpeed: 5.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 6 pedestrians, 12 peoples, 3 bicycles, 30 cars, 3 vans, 2 awning-tricycles, 12 motors, 8.4ms\nSpeed: 3.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 5 pedestrians, 14 peoples, 2 bicycles, 28 cars, 3 vans, 1 tricycle, 1 awning-tricycle, 10 motors, 8.4ms\nSpeed: 3.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 5 pedestrians, 12 peoples, 1 bicycle, 28 cars, 3 vans, 1 awning-tricycle, 13 motors, 8.5ms\nSpeed: 3.9ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 5 pedestrians, 13 peoples, 2 bicycles, 27 cars, 5 vans, 1 awning-tricycle, 8 motors, 8.7ms\nSpeed: 4.6ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 8 pedestrians, 11 peoples, 3 bicycles, 25 cars, 4 vans, 2 awning-tricycles, 9 motors, 8.6ms\nSpeed: 4.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 7 pedestrians, 11 peoples, 1 bicycle, 27 cars, 4 vans, 1 awning-tricycle, 13 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 9 pedestrians, 12 peoples, 27 cars, 5 vans, 1 awning-tricycle, 8 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 960)\n\n0: 544x960 7 pedestrians, 11 peoples, 1 bicycle, 25 cars, 4 vans, 1 awning-tricycle, 9 motors, 8.4ms\nSpeed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 960)\n","output_type":"stream"}]}]}